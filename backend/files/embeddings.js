import { pipeline, env } from "@huggingface/transformers";
import dotenv from "dotenv";

dotenv.config();

// ===== 1ï¸âƒ£ Embedding é…ç½® =====
env.allowLocalModels = true;
env.backends.onnx.wasm.numThreads = 4;
env.backends.onnx.wasm.simd = true;

const EMBEDDING_MODEL = "Xenova/bge-m3";

let embedderPromise = null;

// ===== 2ï¸âƒ£ å•ä¾‹åŠ è½½ Embedding æ¨¡å‹ =====
export async function getEmbedder() {
  if (!embedderPromise) {
    console.log(`ğŸš€ åŠ è½½ Embedding æ¨¡å‹ (${EMBEDDING_MODEL})...`);
    embedderPromise = pipeline("feature-extraction", EMBEDDING_MODEL, {
      quantized: true
    });
  }
  return embedderPromise;
}

// ===== 3ï¸âƒ£ å•æ¡æ–‡æœ¬ embedding =====
export async function embedText(text) {
  const model = await getEmbedder();
  const output = await model(text, { pooling: "mean", normalize: true });
  return Array.from(output.data);
}

// ===== 4ï¸âƒ£ æ‰¹é‡æ–‡æœ¬ embedding =====
export async function embedBatch(texts) {
  const model = await getEmbedder();
  const results = [];

  for (const t of texts) {
    const embedding = await model(t, { pooling: "mean", normalize: true });
    results.push(Array.from(embedding.data));
  }

  return results;
}

// ===== 5ï¸âƒ£ Embedding è‡ªæ£€å‡½æ•° =====
export async function embeddingSelfTest() {
  console.log("ğŸ” æ­£åœ¨è¿›è¡Œ embedding è‡ªæ£€â€¦");
  const testSentences = [
    "Hello world",
    "æµ‹è¯•ä¸­æ–‡å¥å­"
  ];

  const vectors = await embedBatch(testSentences);

  vectors.forEach((v, i) => {
    console.log(`âœ… [${i}] é•¿åº¦: ${v.length}, å‰5ç»´: ${v.slice(0,5).map(n=>n.toFixed(4))}`);
  });

  console.log("âœ… Embedding è‡ªæ£€å®Œæˆ\n");
}
