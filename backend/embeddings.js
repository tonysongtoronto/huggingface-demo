import dotenv from "dotenv";
import { MongoClient } from "mongodb";
import fs from "fs/promises";

import { AnswerPolicy } from "./files/answerPolicy.js";
import {
  generatePrompt,
  formatContext,
  generateSystemPrompt
} from "./files/prompts.js";

import {
  embedText,
  embedBatch,
  embeddingSelfTest
} from "./files/embeddings.js";

dotenv.config();

/* =========================================================
 * 1ï¸âƒ£ LLM API é…ç½®ï¼ˆGroqï¼‰
 * ========================================================= */
const API_PROVIDER = "groq";
const API_KEY = process.env.GROQ_API_KEY;
const API_URL = "https://api.groq.com/openai/v1/chat/completions";
const MODEL_NAME = "llama-3.3-70b-versatile";

/* =========================================================
 * 2ï¸âƒ£ MongoDB
 * ========================================================= */
const client = new MongoClient(process.env.MONGO_URI);

/* =========================================================
 * 3ï¸âƒ£ LLM è°ƒç”¨ï¼ˆå•è½®ï¼‰
 * ========================================================= */
async function callFreeAPI(prompt, systemPrompt = null) {
  if (!API_KEY) throw new Error("ç¼ºå°‘ GROQ_API_KEY");

  const messages = [];
  if (systemPrompt) {
    messages.push({ role: "system", content: systemPrompt });
  }
  messages.push({ role: "user", content: prompt });

  const response = await fetch(API_URL, {
    method: "POST",
    headers: {
      "Content-Type": "application/json",
      Authorization: `Bearer ${API_KEY}`
    },
    body: JSON.stringify({
      model: MODEL_NAME,
      messages,
      max_tokens: 250,
      temperature: 0.65
    })
  });

  if (!response.ok) {
    throw new Error(await response.text());
  }

  const data = await response.json();
  return data.choices[0].message.content.trim();
}

/* =========================================================
 * 4ï¸âƒ£ LLM è°ƒç”¨ï¼ˆå¤šè½®ï¼Œåƒå†å²ï¼‰
 * ========================================================= */
async function callFreeAPIWithHistory(messages) {
  const response = await fetch(API_URL, {
    method: "POST",
    headers: {
      "Content-Type": "application/json",
      Authorization: `Bearer ${API_KEY}`
    },
    body: JSON.stringify({
      model: MODEL_NAME,
      messages,
      max_tokens: 250,
      temperature: 0.65
    })
  });

  if (!response.ok) {
    throw new Error(await response.text());
  }

  const data = await response.json();
  return data.choices[0].message.content.trim();
}

/* =========================================================
 * 5ï¸âƒ£ Mongo Collection
 * ========================================================= */
async function getCollection() {
  await client.connect();
  return client
    .db(process.env.MONGO_DB || "rag_test")
    .collection("documents");
}

/* =========================================================
 * 6ï¸âƒ£ å‘é‡æœç´¢ï¼ˆä½¿ç”¨ embeddings.jsï¼‰
 * ========================================================= */
async function searchVector(col, query, k = 3) {
  const qEmbedding = await embedText(query);

  const cursor = col.aggregate([
    {
      $vectorSearch: {
        index: "vector_index",
        path: "embedding",
        queryVector: qEmbedding,
        numCandidates: 100,
        limit: k
      }
    },
    { $addFields: { score: { $meta: "vectorSearchScore" } } },
    { $project: { _id: 0, content: 1, score: 1 } }
  ]);

  return cursor.toArray();
}

/* =========================================================
 * 7ï¸âƒ£ AnswerPolicy
 * ========================================================= */
const policy = new AnswerPolicy({
  highThreshold: 0.9,
  lowThreshold: 0.85,
  minGapForStrict: 0.05
});

/* =========================================================
 * 8ï¸âƒ£ å•è½® RAGï¼ˆä¿æŒåŸé€»è¾‘ï¼‰
 * ========================================================= */
async function ragAnswer(col, question) {
  const topDocs = await searchVector(col, question);
  const decision = policy.decide(topDocs);
  const context = formatContext(topDocs);
  const topScore = topDocs[0]?.score || 0;

  const prompt = generatePrompt(
    decision.answer_type,
    question,
    context,
    topScore
  );
  const systemPrompt = generateSystemPrompt(decision.answer_type);

  const answer = await callFreeAPI(prompt, systemPrompt);

  return {
    answer,
    answer_type: decision.answer_type,
    confidence: decision.confidence,
    sources: topDocs
  };
}

/* =========================================================
 * ğŸ”¥ 9ï¸âƒ£ å¤šè½® RAGï¼ˆåƒå†å²ï¼‰
 * ========================================================= */
async function ragAnswerWithHistory(col, question, sessionMessages) {
  const topDocs = await searchVector(col, question);
  const decision = policy.decide(topDocs);
  const context = formatContext(topDocs);
  const topScore = topDocs[0]?.score || 0;

  const prompt = generatePrompt(
    decision.answer_type,
    question,
    context,
    topScore
  );
  const systemPrompt = generateSystemPrompt(decision.answer_type);

  const messages = [
    { role: "system", content: systemPrompt }
  ];

  if (sessionMessages.length > 0) {
    messages.push({
      role: "system",
      content: "ä»¥ä¸‹æ˜¯ä¹‹å‰çš„å¯¹è¯è®°å½•ï¼Œä»…ä¾›å‚è€ƒï¼Œä¸ä¿è¯å…¶æ­£ç¡®æ€§ã€‚"
    });
    messages.push(...sessionMessages);
  }

  messages.push({ role: "user", content: prompt });

  const answer = await callFreeAPIWithHistory(messages);

  return {
    answer,
    answer_type: decision.answer_type,
    confidence: decision.confidence,
    sources: topDocs
  };
}

/* =========================================================
 * ğŸ” 10ï¸âƒ£ å¤šè½®å›å½’æµ‹è¯•
 * ========================================================= */
async function runMultiTurnRagTests(col) {
  const suites = JSON.parse(
    await fs.readFile("./Data/multi_turn_tests.json", "utf-8")
  );

  console.log("\n=== ğŸ§ª å¤šè½® RAG å›å½’æµ‹è¯• ===\n");

  for (const suite of suites) {
    console.log(`ğŸ§© åœºæ™¯ï¼š${suite.name}`);
    console.log("-".repeat(60));

    const sessionMessages = [];

    for (let i = 0; i < suite.turns.length; i++) {
      const q = suite.turns[i].q;
      console.log(`\nâ–¶ï¸ ç¬¬ ${i + 1} è½®ï¼š${q}`);

      const result = await ragAnswerWithHistory(
        col,
        q,
        sessionMessages
      );

      console.log(`âœ… å›ç­”ï¼š${result.answer}`);
      console.log(
        `ğŸ“Š ç±»å‹ï¼š${result.answer_type} | ç½®ä¿¡åº¦ï¼š${result.confidence.toFixed(3)}`
      );

      sessionMessages.push(
        { role: "user", content: q },
        { role: "assistant", content: result.answer }
      );
    }
  }

  console.log("\n=== âœ… å¤šè½®æµ‹è¯•ç»“æŸ ===\n");
}

/* =========================================================
 * 1ï¸âƒ£1ï¸âƒ£ ç§å­æ•°æ®ï¼ˆæ‰¹é‡ embeddingï¼‰
 * ========================================================= */
async function seedData(col, docs) {
  console.log("ğŸ› ï¸ åŒæ­¥çŸ¥è¯†åº“â€¦");

  const existing = await col.find({}, { projection: { content: 1 } }).toArray();
  const existingSet = new Set(existing.map(d => d.content));

  const newDocs = docs.filter(d => !existingSet.has(d));
  if (newDocs.length === 0) {
    console.log("âœ… çŸ¥è¯†åº“å·²æ˜¯æœ€æ–°\n");
    return;
  }

  const vectors = await embedBatch(newDocs);

  const payload = newDocs.map((text, i) => ({
    content: text,
    embedding: vectors[i],
    createdAt: new Date()
  }));

  await col.insertMany(payload);
  console.log(`âœ… æ–°å¢ ${payload.length} æ¡çŸ¥è¯†\n`);
}

/* =========================================================
 * 1ï¸âƒ£2ï¸âƒ£ main
 * ========================================================= */
async function main() {
  try {
    console.log("ğŸ” Embedding è‡ªæ£€ä¸­â€¦");
    await embeddingSelfTest();

    const col = await getCollection();
    const data = JSON.parse(await fs.readFile("./Data/data.json", "utf-8"));
    const tests = JSON.parse(await fs.readFile("./Data/tests.json", "utf-8"));

    await seedData(col, data);

    console.log("\n=== ğŸ¤– å•è½® RAG æµ‹è¯• ===\n");

    for (const q of tests) {
      const r = await ragAnswer(col, q);
      console.log(`Q: ${q}`);
      console.log(`A: ${r.answer}`);
      console.log(
        `ğŸ“Š ç±»å‹ï¼š${r.answer_type} | ç½®ä¿¡åº¦ï¼š${r.confidence.toFixed(3)}\n`
      );
    }

    await runMultiTurnRagTests(col);

  } catch (e) {
    console.error("âŒ é”™è¯¯ï¼š", e.message);
  } finally {
    await client.close();
  }
}

main();
